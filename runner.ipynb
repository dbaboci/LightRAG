{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from lightrag import LightRAG\n",
    "from lightrag.base import DocStatus\n",
    "from lightrag.llm.openai import openai_complete_if_cache, openai_embed\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "\n",
    "LLM_BASE_URL = (\n",
    "    os.getenv(\"OPENAI_COMPAT_BASE_URL\")\n",
    "    or os.getenv(\"LLM_BINDING_HOST\")\n",
    "    or os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "LLM_API_KEY = (\n",
    "    os.getenv(\"OPENAI_COMPAT_API_KEY\")\n",
    "    or os.getenv(\"LLM_BINDING_API_KEY\")\n",
    "    or os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "LLM_MODEL = os.getenv(\"OPENAI_COMPAT_MODEL\") or os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "EMBED_BASE_URL = (\n",
    "    os.getenv(\"OPENAI_COMPAT_EMBED_BASE_URL\")\n",
    "    or os.getenv(\"EMBEDDING_BINDING_HOST\")\n",
    "    or LLM_BASE_URL\n",
    ")\n",
    "EMBED_API_KEY = (\n",
    "    os.getenv(\"OPENAI_COMPAT_EMBED_API_KEY\")\n",
    "    or os.getenv(\"EMBEDDING_BINDING_API_KEY\")\n",
    "    or LLM_API_KEY\n",
    ")\n",
    "EMBED_MODEL = os.getenv(\"OPENAI_COMPAT_EMBED_MODEL\") or os.getenv(\n",
    "    \"EMBEDDING_MODEL\", \"text-embedding-3-small\"\n",
    ")\n",
    "EMBED_DIM = int(os.getenv(\"EMBEDDING_DIM\", \"1536\"))\n",
    "EMBED_MAX_TOKENS = int(os.getenv(\"MAX_EMBED_TOKENS\", \"8192\"))\n",
    "\n",
    "if not LLM_API_KEY:\n",
    "    raise RuntimeError(\n",
    "        \"Provide LLM credentials via OPENAI_COMPAT_API_KEY, LLM_BINDING_API_KEY, or OPENAI_API_KEY.\"\n",
    "    )\n",
    "if not EMBED_API_KEY:\n",
    "    raise RuntimeError(\n",
    "        \"Provide embedding credentials via OPENAI_COMPAT_EMBED_API_KEY, EMBEDDING_BINDING_API_KEY, or OPENAI_COMPAT_API_KEY.\"\n",
    "    )\n",
    "\n",
    "async def compat_llm(prompt, system_prompt=None, history_messages=None, **kwargs):\n",
    "    return await openai_complete_if_cache(\n",
    "        LLM_MODEL,\n",
    "        prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        history_messages=history_messages or [],\n",
    "        base_url=LLM_BASE_URL or \"https://api.openai.com/v1\",\n",
    "        api_key=LLM_API_KEY,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "async def compat_embed_func(texts: list[str]):\n",
    "    return await openai_embed(\n",
    "        texts,\n",
    "        model=EMBED_MODEL,\n",
    "        base_url=EMBED_BASE_URL or \"https://api.openai.com/v1\",\n",
    "        api_key=EMBED_API_KEY,\n",
    "    )\n",
    "\n",
    "compat_embed = EmbeddingFunc(\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    max_token_size=EMBED_MAX_TOKENS,\n",
    "    func=compat_embed_func,\n",
    ")\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=\"demo2_storage\",\n",
    "    embedding_func=compat_embed,\n",
    "    llm_model_func=compat_llm,\n",
    ")\n",
    "\n",
    "INPUT_DIR = Path(\"input_docs\")\n",
    "if not INPUT_DIR.exists():\n",
    "    raise FileNotFoundError(\"input_docs directory not found. Add your .txt files before running.\")\n",
    "\n",
    "FILENAME_PATTERN = re.compile(r\"(?P<law>\\d+)_(?P<year>\\d{4})__(?P<article>\\d+)\\.txt\")\n",
    "\n",
    "docs: list[dict[str, object]] = []\n",
    "doc_ids: list[str] = []\n",
    "file_paths_arg: list[str] = []\n",
    "\n",
    "for txt_path in sorted(INPUT_DIR.glob(\"*.txt\")):\n",
    "    match = FILENAME_PATTERN.fullmatch(txt_path.name)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Unexpected file name format: {txt_path.name}\")\n",
    "    law_number = int(match.group(\"law\"))\n",
    "    year = match.group(\"year\")\n",
    "    article_number = int(match.group(\"article\"))\n",
    "\n",
    "    ligji_name = f\"Ligji {law_number}/{year}\"\n",
    "    neni_name = f\"Neni {article_number} | {ligji_name}\"\n",
    "\n",
    "    manual_graph = {\n",
    "        \"entities\": [\n",
    "            {\n",
    "                \"entity_name\": ligji_name,\n",
    "                \"entity_type\": \"ligj\",\n",
    "            },\n",
    "            {\n",
    "                \"entity_name\": neni_name,\n",
    "                \"entity_type\": \"neni\",\n",
    "            },\n",
    "        ],\n",
    "        \"relationships\": [\n",
    "            {\n",
    "                \"src_id\": neni_name,\n",
    "                \"tgt_id\": ligji_name,\n",
    "                \"description\": \"part_of\",\n",
    "                \"relation_type\": \"part_of\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    docs.append(\n",
    "        {\n",
    "            \"content\": txt_path.read_text(encoding=\"utf-8\"),\n",
    "            \"manual_graph\": manual_graph,\n",
    "            \"metadata\": {\n",
    "                \"ligji_name\": ligji_name,\n",
    "                \"neni_name\": neni_name,\n",
    "                \"source_file\": txt_path.name,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    doc_ids.append(f\"doc-{txt_path.stem}\")\n",
    "    file_paths_arg.append(str(txt_path))\n",
    "\n",
    "if not docs:\n",
    "    raise RuntimeError(\"No .txt files found in input_docs directory.\")\n",
    "\n",
    "await rag.initialize_storages()\n",
    "await initialize_pipeline_status()\n",
    "\n",
    "track_id = await rag.ainsert(docs, ids=doc_ids, file_paths=file_paths_arg)\n",
    "print(\"Track:\", track_id)\n",
    "\n",
    "processed = await rag.doc_status.get_docs_by_status(DocStatus.PROCESSED)\n",
    "for doc_id, status in processed.items():\n",
    "    print(doc_id, status.chunks_list)\n",
    "\n",
    "await rag.finalize_storages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2db7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
